# Overview

&nbsp;&nbsp;&nbsp;&nbsp;In this course, you will explore the fundamental principles and techniques behind ETL and ELT processes.

## Week 1: Data Preprocessing Techniques

&nbsp;&nbsp;&nbsp;&nbsp;You will learn to:
1. describe what an ETL pipeline is 
2. why ELT is an emergent trend
3. describe the trending shift from ETL to ELT
4. List examples of raw data sources
5. Name data loading techniques
6. Differentiate batch loading from stream loading
7. explore how to construct a basic ETL data pipeline from scratch using Bash Shell-Scripting, and explore use cases for the two main paradigms within data pipeline engineering: batch and streaming data pipelines

## Week 2: ETL and Data Pipelines Tools and Techniques

&nbsp;&nbsp;&nbsp;&nbsp;You will learn to:
1. describe how shell scripting can be used to implement and ETl pipeline
2. describe what a data pipeline is
3. describe data pipeline solutions for mitigating data flow bottlenecks
4. differentiate between batch and streaming data pipelines
5. discuss data pipeline technologies

## Week 3: Building Data Pipelines using Airflow

&nbsp;&nbsp;&nbsp;&nbsp;You will learn to:
1. list the main principles of Apache Airflow
2. interpret airflow pipelines as python scripts that define airflow DAG objects
3. list key advantages of defining workflows as code
4. identify current DAGs in your environment and set up dependencies amongst tasks
5. Use logging capabilities to monitor the task status and diagnose problems with DAG runs

## Week 4: Building Streaming Pipelines using Kafka

&nbsp;&nbsp;&nbsp;&nbsp;You will learn to:
1. list the main componenets of an ESP 
2. recognize Apache Kafka as an event streaming platform
3. describe an end-to-end event streaming pipeline example
4. describe what the Kafka Streams API is

## Project 5: Final Project

&nbsp;&nbsp;&nbsp;&nbsp;You will be to complete a project to create an ETL pipeline using an Airflow DAG and build a streaming ETL pipeline using Kafka
